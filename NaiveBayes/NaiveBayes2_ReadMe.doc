NaiveBayes2_ReadMe.doc
LiangZHANG
2015-8-6
Liangzxdu@foxmail.com

关键词：朴素贝叶斯算法，文档分类，拉普拉斯平滑，停用词表

这是NaiveBayes2.py代码文件的设计手册，该代码文件（NaiveBayes2.py）和本设计手册（NaiveBayes2_ReadMe.doc）同样位于NaiveBayes文件夹中。

NaiveBayes2.py的数据（邮件数据）来自于data2文件夹（同样位于NaiveBayes Project文件夹中），数据如下所述：

    第一行的0/1表示该文本是否为垃圾邮件(0为垃圾邮件，1为正常邮件)
    从第二行到最后都是邮件正文

同时为了防止统计数据不足导致的概率值为零的情况，我们采用Laplace Smooth来避免（一开始没用，正确率是90%，然后用了之后，发现也有弊端）。同时，使用exp/log来进行概率值映射，防止连乘导致的下溢为零。

程序的基本思路：
1.扫描全文档，构建词典（单独写一个过滤函数，后面也会用到）
2.构建参数矩阵
3.构建概率矩阵（Laplace_Smooth and exp/log）
4.基于测试集进行测试（Prediction）

主要函数剖析：
1.Scan_Text() :
　　主要工作：对整个文本集合中的所有文本（来自“data2文件夹”）进行扫描，预处理（过			滤函数Filter，其中包含了去除停用词）后，按空格进行切分（split），得到词			表/词典，最终得到一个排好序的list
　　输入：	NULL（或者也可以是路径地址）
　　输出：	一个排好序的list词典L，汇集了所有文本中的全部单词（停用词除外）
　　
2.Filter() :
　　主要工作：对于输入的字符串，过滤掉其中的数字，标点符号，并将大写字母转换成小写			形式，便于后期的处理（由于python中字符串是不可变的，所以需要将字符串			先转换为list，处理完后再从list转换回字符串，最终返回该字符串）。后来加			上停用词过滤模块（Remove_Stop_Word）。
　　输入：	待过滤的字符串str
　　输出：	过滤之后的字母表list

3.Create_Matrix():
　　主要工作：对训练数据集（data2/TrainSet）进行扫描，对每一个文档，读取后，用Filter				过滤，得到该文档包含的单词的list。随后对list中的每个单词，每出现一次，			便在计数矩阵中将其计数加一。有两个计数矩阵，分别是y计数矩阵和word-y			计数矩阵(size : 1*2 and len(L)*2)，最后返回这两个计数矩阵。
　　输入：	词典L
　　输出：	两个计数矩阵(Matrix_Y and Matrix_WordY)，分别是1*2和len(L)*2
　　
4.Calculate_Probability() :
　　主要工作： 由上一步得到的计数函数计算各个词项出现的概率（直接除以出现的总数即可），			同时进行Laplace_Smooth和log/exp映射。
　　输入：	词典L，word-y计数矩阵（Matrix_WordY）
　　输出：	word-y概率矩阵（同样是Matrix_WordY）

5.Prediction() :
　　主要工作：从测试集中(data2/TestSet)读取数据，预处理后(Filter过滤)，根据上面得到的				word-y概率矩阵，通过朴素贝叶斯算法来计算P0和P1的概率（连乘），并将			文档分到概率大的那个类别中。并且与flag进行对比(flag是文档的第一行，是			其应该被分到的类别，0/1)，每当flag与朴素贝叶斯算法得出的值不相等，				count_wrong便加一，最终用count_wrong/count_all，得到误分率。
　　输入：    两个上面统计出的概率矩阵矩阵，分别是Matrix_Y，Matrix_WordY，用来参与			朴素贝叶斯算法，预测文档的分类。
　　输出：    NULL，倒是会通过屏幕打印出误分率

6.Remove_Stop_Word():
　　主要工作：根据stop_word集合，对传进来的字符串list进行过滤，去除其中的停用词。使			得后续的预测更准确，去除的时候要注意，因为文档中可能多次包含某个相同			的停用词，所以不可用list.remove()，要用python的列推导式来更新。
　　输入：    一个包含字符串的list，也就是每封邮件的内容
　　输出：    一个包含字符串的list，只不过去除了其中的停用词
　　
　　
Ps1:暂时未使用Laplace_Smooth和exp/log映射，当前的误分率是10%，使用后应该会更低――2015-8-7-16:50

Ps2:使用了Laplace_Smooth和exp/log映射，然而误分率还是10%，挺疑惑的，感觉是训练数据太少的缘故。    2015-8-11 发现有时候使用拉普拉斯平滑反而会对分类的精确度造成影响，这是因为非垃圾邮件一般情况下比垃圾邮件要长，单词量要大。导致在Matrix_WordY矩阵中本来训练集中没出现的词（在Matrix_WordY矩阵中是一行0,0，应该对测试集的分类没贡献的），结果，因为非垃圾邮件单词量多，导致平滑后本来是0,0 的变成了0.011,0.01（分别表示该词对垃圾邮件、非垃圾邮件预测所做的贡献）。这样，在连乘后，分类器会自动偏向于单词量少的垃圾邮件，导致分类错误！在去掉Laplace_Smooth但使用了exp映射和停用词表后，分类准确率达到了100%！所以，我们不能盲目相信前人的话，还是要多试多练。。。

Ps3:去除停用词后可能误分率会下降。    2015-8-11 使用了停用词表，和exp配合使用，可以降低误分率，stop_word还是有用的！

Ps4:采用tf-idf可能会更好！(暂时还没尝试~)2015-8-12

laplace_smooth	Stop_word	exp	正确率
0	0	0	90%
0	0	1	90%
0	1	0	90%
0	1	1	100%
1	0	0	90%
1	0	1	90%
1	1	0	90%
1	1	1	90%


附录：纸质版设计文档电子照片：



